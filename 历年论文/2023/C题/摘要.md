# 1. Revitalizing a Classic Game: Uncovering the Secrets of Wordle through Data Analysis (2300348)
## 

In the digital era, language is often conveyed through abbreviations, emojis, and voice messages. However, the Wordle game, provided by the New York Times, offers a chance to return to the basics of language. Thus, we conducted a data analysis of the results yielded by Wordle.

在数字时代，语言通常通过缩写、表情符号和语音消息传达。然而，《纽约时报》提供的Wordle游戏为我们提供了回归语言基础的机会。因此，我们对Wordle产生的结果进行了数据分析。

Firstly, we established a GRU Prediction Model to predict the number of reported results on March 1, 2023. The model uses the effective Gated Recurrent Unit (GRU) algorithm. Therefore, predictions made by the training set to the testing have the relative error rate of 2.1569%, and the relative RESE of 6.4957%, indicating a good accuracy of the model predictions. The predicted interval for the number of reported results on March 1, 2023 is 20367 ± 2.01569%.

首先，我们建立了一个GRU预测模型，以预测2023年3月1日报告的结果数量。该模型使用了有效的门控循环单元（GRU）算法。因此，训练集对测试集的预测具有相对误差率为2.1569％和相对RESE为6.4957％，表明模型预测的准确性良好。对于2023年3月1日报告的结果数量，预测区间为20367 ± 2.01569％。

Secondly, we conducted a data analysis on the attributes of words and score defined by the percentage of scores. Then, we defined four attributes of the words: word frequency, sum of letter frequencies,repetition patterns of letters(2/3 or none), and main part of speech. For the first two, we performed regression analysis with the variable "score". The Pearson correlation coefficient between fword and score is -0.3165, and fletter and score-0.4005.rep and pos can be used to categorize the words.The box plot results showed that the Median difference of the box plot for rep was 0.13004, while pos was only 0.05973.Therefore, we believe that fword, fletter, and rep can affect the percentage of scores, while pos can not.

其次，我们对单词的属性和得分进行了数据分析，得分以百分比表示。然后，我们定义了单词的四个属性：单词频率，字母频率之和，字母重复模式（2/3或无）以及主要词性。对于前两者，我们使用变量“score”进行回归分析。fword和score之间的皮尔逊相关系数为-0.3165，fletter和score为-0.4005。rep和pos可用于对单词进行分类。箱线图结果显示，rep的中位数差异为0.13004，而pos仅为0.05973。因此，我们认为fword、fletter和rep可以影响得分的百分比，而pos则不能。

Thirdly, we have developed GSRF Prediction Model to predict the percentages of 1 to X for EERIE on March 1, 2023. The Grid-Search Random Forest (GSRF) algorithm is an improved random forest algorithm by using the best combination of hyperparameters. We selected the three parameters, $f_{word}$, $f_{letter}$, and rep as inputs for the model. The model’s training results show a MSE of 20.70641 and a MAE of 3.24388,indicating good predictive performance.(Table 10) The predicted results for EERIE are (1,7,23,30,23,13,3). In addition, we conducted sensitivity analysis by adding Gaussian noise to $f_{word}$ and $f_{letter}$ separately, and the results showed that the model has low sensitivity and is thus highly stable.

第三，我们开发了GSRF预测模型，以预测2023年3月1日EERIE的1到X的百分比。Grid-Search Random Forest（GSRF）算法是通过使用超参数的最佳组合改进的随机森林算法。我们选择了三个参数，$f_{word}$、$f_{letter}$和rep作为模型的输入。模型的训练结果显示MSE为20.70641，MAE为3.24388，表明有良好的预测性能。EERIE的预测结果是（1,7,23,30,23,13,3）。此外，我们通过分别对$f_{word}$和$f_{letter}$添加高斯噪声进行敏感性分析，结果显示该模型的敏感性较低，因此非常稳定。

Fourthly, Difficulty Rate Classification Model using the K-Means++are conducted. We first defined the difficulty date δ of each word first. The difficulty rate of EERIE is 0.35916 by predicted distribution. Then, we use K-Means++, to analyze the δ of each word and obtained five levels of difficulty (Table11). EERIE was classified into the third level. Finally, we compared the model’s classification with the manul difficulty ratings for a subset of sampled words and achieved a match
rate of 93.33%, confirming the accuracy of the model.

第四，使用K-Means++进行难度率分类模型。我们首先定义了每个单词的难度日期δ。通过预测的分布，EERIE的难度率为0.35916。然后，我们使用K-Means++分析每个单词的δ，并得到了五个难度级别。EERIE被分类为第三级。最后，我们将模型的分类与对一部分抽样单词的手动难度评分进行比较，取得了93.33%的匹配率，证实了模型的准确性。

Finally, we explored two other data features.Afterwards, a letter supported by our stable models has been written for the Puzzle Editor of the New York Times.

最后，我们探索了其他两个数据特征。随后，我们为《纽约时报》的拼图编辑撰写了一封由我们稳定模型支持的信件。

**Keywords**: GRU;Regression Analysis;Box Plot Analysis;GSRF;K-Means++

关键词：GRU；回归分析；箱线图分析；GSRF；K-Means++

# 2. Crack the Wordle Puzzle: Word Attribute Analysis Approaches (2301192)
## 突破Wordle难题：Word属性分析方法

In the past 600 days, a five-letter puzzle game called ”Wordle” has been launching a blast ofupsurge on Twitter. Wordle players’ scores reports are crucial for managers as they provide valuable information for evaluating game difficulty,predicting player numbers and making timelyadjustments. To better analyze the reports and provide game improvement suggestions, we conduct in-depth and close studies on this topic from multiple perspectives and levels. 

在过去的600天里，一款名为“Wordle”的五个字母的益智游戏在Twitter上掀起了一股热潮。Wordle玩家的得分报告对游戏经理至关重要，因为它们为评估游戏难度、预测玩家数量和及时调整提供了宝贵的信息。为了更好地分析这些报告并提出改进建议，我们从多个角度和层面对这个话题进行了深入而密切的研究。

Firstly, to explain the changes in the number of Wordle reports and make predictions, we use an analogy between playing Wordle and the spread of infectious diseases. We compare playingWordle with infection, players with infected individuals, individuals who have not played Wordle for a long time with susceptible individuals, individuals who have become tired of the game with recovered individuals, sharing on Twitter with transmission, and quitting the game with recovery. Based on these assumptions, we use the SIRS model to fit the curve and explain the overall trend. We also use the Prophet model to insert breakpoints to explain data oscillations and provide a prediction interval for future data. Model evaluation results show that our model has high interpretability and accuracy.

首先，为了解释Wordle报告数量的变化并进行预测，我们使用了玩Wordle与传染病传播之间的类比。我们将玩Wordle与感染、玩家与被感染者、长时间不玩Wordle的个体与易感个体、对游戏感到厌倦的个体与康复个体、在Twitter上分享与传播，以及退出游戏与康复进行了比较。基于这些假设，我们使用SIRS模型拟合曲线并解释整体趋势。我们还使用Prophet模型插入断点来解释数据振荡，并为未来的数据提供预测区间。模型评估结果显示我们的模型具有很高的解释性和准确性。

Next, we extract various word attributes from a word database containing a large amount of corpus information and use multiple linear regression to investigate whether there is a relationship between word attributes and Hard-Mode scores. We then test the significance of the model based on the F-statistic. The result shows no significant correlation between these two factors.

接下来，我们从包含大量语料库信息的单词数据库中提取各种单词属性，并使用多元线性回归研究单词属性与Hard-Mode得分之间是否存在关系。然后，我们基于F统计量测试模型的显著性。结果显示这两个因素之间没有显著的相关性。

Besides, we construct a BP neural network model based on the previously extracted word attributes to predict the distribution of the number of word guesses. The evaluation results show that the model has high prediction accuracy and efficiency, laying a solid foundation for next step analysis.

此外，我们基于先前提取的单词属性构建了一个BP神经网络模型，以预测单词猜测次数的分布。评估结果显示该模型具有较高的预测准确性和效率，为下一步的分析奠定了坚实的基础。

Furthermore, we use K-means++ clustering algorithm to divide words into three categories: easy, medium, and hard. We analyze the relationship between word attributes and difficulty to classify solution words by difficulty. We find that the difficulty of a word is closely related to the number of different letters in the word, the sum of letter frequencies, and the breadth of
usage of the word in different fields, but there is no significant evidence of a correlation between difficulty and word frequency. Combined with the previous BP neural network model, we can accurately classify words.

此外，我们使用K-means++聚类算法将单词分为三类：容易、中等和困难。我们分析单词属性与难度之间的关系，以难度分类解决方案单词。我们发现单词的难度与单词中不同字母的数量、字母频率之和以及单词在不同领域的使用广度密切相关，但没有明显的证据表明难度与单词频率之间存在相关性。结合先前的BP神经网络模型，我们可以准确地对单词进行分类。

In addition, we find that common words such as ”mummy” and ”watch” have a higher guessing difficulty, and there is also a certain correlation between the first letter of a word and its guessing difficulty.

此外，我们发现像“mummy”和“watch”这样的常见词具有较高的猜测难度，而单词的第一个字母与其猜测难度之间也存在一定的相关性。

Finally, we present predictive data and improvement suggestions to the editors of The New York Times to assist in improving Wordle and boosting the appealing feature of the game.

最后，我们向《纽约时报》的编辑呈现预测数据和改进建议，以帮助改进Wordle并提升游戏的吸引力。

**Keywords**: Prophet; SIRS; Multiple Linear Regression; BP Neural Network; K-Means++

关键词：Prophet；SIRS；多元线性回归；BP神经网络；K-Means++

# 3. Viral Spread Characteristics and Difficulty Determinants of Wordle Modeling Based on Differential Equations and K-nearest Neighbors (2307166)
## 基于微分方程和K最近邻的Wordle建模中的病毒传播特征和难度因素

Recently, Wordle, a puzzle game, has been spreading widely around the world and has a high level of buzz on social media such as Twitter. Understanding the spread mechanism of the Wordle crazeand the factors influencing the difficulty of the game may shed some light on important issues such as understanding the viral spread in the Internet era and the way the human brain associates words.

最近，Wordle，一款益智游戏，在全球范围内广泛传播，并在Twitter等社交媒体上引起了高度关注。了解Wordle狂潮的传播机制以及影响游戏难度的因素可能为理解互联网时代的病毒传播和人类大脑联想词汇等重要问题提供一些启示。

We developed an epidemiology-like differential equation model describing the variation in the total number of reports based on the SIR model and fitted the model using a genetic algorithm to minimize the MSE. We then used the fitted model to make a point forecast of the total number of reports on March 1, 2023. To obtain confidence intervals for the predictions, we used the Bootstrap method. To improve the speed of fitting the Bootstrap sample, we used the computationally faster Nelder-Mead
method, based on the same initial parameters optimized by a genetic algorithm. The 1000 Bootstrap estimates were arranged from smallest to largest, and the 25th and 975th estimates were selected as the lower and upper bounds of the prediction interval.

我们开发了一种类似流行病学的微分方程模型，描述了总报告数量的变化，基于SIR模型，并使用遗传算法拟合模型以最小化均方误差（MSE）。然后，我们使用拟合模型对2023年3月1日的总报告数量进行点预测。为了获取预测的置信区间，我们使用了Bootstrap方法。为了提高拟合Bootstrap样本的速度，我们使用了计算速度较快的Nelder-Mead方法，该方法基于遗传算法优化的相同初始参数。将1000个Bootstrap估计从小到大排列，选择第25个和第975个估计值作为预测区间的下限和上限。

Two characteristic lexical internal features are built in this paper. We define regularity and purity (negentropy) features by assuming first-order Markovianity of the occurrence probability of characters in the English lexicon. All indications are that they are indeed related to the difficulty of the lexicon being guessed. Regularities such as the number of repeated characters and the frequency of vocabulary use in everyday life are also used in this paper for prediction and interpretation.

本文构建了两个特征词汇内部特征。我们通过假设英语词汇中字符出现概率的一阶马尔可夫性，定义了规律性和纯度（负熵）特征。所有迹象都表明它们与被猜测的词汇的难度确实相关。本文还使用诸如重复字符的数量和词汇在日常生活中的使用频率等规律性特征进行预测和解释。

KNN regression has the excellent property of ensuring that the predicted distribution still sums to zero, so we use the KNN regression model to make predictions about the distribution of Wordle scores. The covariance matrix is widely used in this paper for initial selection of variables and determining the relationship between variables. In KNN regression, we use the covariance matrix to select independent variables that are significantly correlated with the distribution and use cross-validation to select the optimal independent variables and K values. To predict the future distribution of scores for a particular puzzle word, we again used the bootstrap method to obtain 95% confidence intervals.

K最近邻回归具有确保预测分布仍然总和为零的优点，因此我们使用K最近邻回归模型对Wordle得分的分布进行预测。协方差矩阵在本文中被广泛用于变量的初始选择和确定变量之间的关系。在K最近邻回归中，我们使用协方差矩阵选择与分布显著相关的独立变量，并使用交叉验证选择最佳的独立变量和K值。为了预测特定拼图单词的未来得分分布，我们再次使用Bootstrap方法获取95%的置信区间。

We used the median scores of Wordle players to measure the difficulty of the words in the puzzle, classifying the difficulty as ‘easy’, ‘normal’, and ‘hard’. We initially screened features that were significantly correlated with difficulty based on the covariance matrix, used a KNN classifier to classify the features based on the initial screening, and selected the K value with the highest prediction accuracy after cross-validation. The results show that the features can effectively predict the difficulty classification of words. For the prediction of word difficulty, we used the KNN classifier and the difficulty-related features we established to assign them to existing categories.

我们使用Wordle玩家的中位得分来衡量拼图中单词的难度，将难度分为“容易”、“正常”和“困难”。我们首先根据协方差矩阵筛选与难度显著相关的特征，使用K最近邻分类器根据初始筛选对特征进行分类，并在交叉验证后选择具有最高预测准确性的K值。结果表明，这些特征能够有效预测单词的难度分类。对于单词难度的预测，我们使用K最近邻分类器和我们建立的与难度相关的特征将其分配到现有类别中。

In further exploration of the data, our most important finding is that the variation in the percentage of Hard Mode shows a high degree of similarity to the variation in the faithful players assumed in our initially built contagion-like model, which somewhat corroborates the soundness of our model.

在进一步探索数据时，我们最重要的发现是Hard Mode百分比的变化与我们最初构建的类似传染模型中假设的忠实玩家的变化具有高度相似性，这在某种程度上证实了我们模型的合理性。

# 4. Words Behind Wordle: Puzzle Game Analysis Using Machine Learning and Time Series Theory (2307946)
## 揭示Wordle背后的文字：使用机器学习和时间序列理论进行益智游戏分析

Wordle is a popular puzzle currently offered daily by New York Times. Players try to solve the puzzle by guessing a five-letter word in six tries or less, receiving feedbackwith every guess. Making full use of relative information can effectively help editors to improve operational performance.

Wordle是《纽约时报》每日提供的一款热门益智游戏。玩家通过猜测一个五个字母的单词，在六次或更少的尝试中解决拼图，每次猜测都会收到反馈。充分利用相关信息可以有效帮助编辑提高运营性能。

Firstly, to explain the variation and predict the future value, a time series model based on the number of reported results is introduced. After determining the optimal groups of orders, ARIMA(0,1,1) model is used to forecast the prediction interval of the number of reported results on March 1, 2023, which is [10139.23, 30808.07](80% confidence). To find out if any attributes of the word affect the hard mode percentage, a words attributes system and a LightGBM model are introduced. The results show that there are some lag attributes that have some but less effect than lag Hard Mode percentage itself.

首先，为了解释变化并预测未来值，引入了一个基于报告结果数量的时间序列模型。在确定最佳阶数组合后，使用ARIMA(0,1,1)模型预测了2023年3月1日报告结果数量的预测区间，为[10139.23, 30808.07]（80%置信度）。为了找出单词的任何属性是否影响Hard Mode百分比，引入了一个单词属性系统和一个LightGBM模型。结果显示，有一些滞后属性对Hard Mode百分比有一些影响，但比滞后Hard Mode百分比本身的影响要小。

Secondly, to predict the associated percentages of (1, 2, 3, 4, 5, 6, X), two models are established based on GBDT and MMoE. The results show that the MMoE model significantly outperforms the GBDT model, with MSE of 145. Then, we attemptd to improve the model by using data augmentation and feature engineering methods. The former leads to a large amount of noise, which fails to achieve the expected effect, and the latter slightly improves the model performance. The prediction of the final model for the word EERIE is (0.649, 7.579, 26.298, 32.614, 20.930, 9.63, 2.298).

其次，为了预测（1、2、3、4、5、6、X）的相关百分比，建立了基于GBDT和MMoE的两个模型。结果表明，MMoE模型明显优于GBDT模型，MSE为145。然后，我们尝试通过使用数据增强和特征工程方法来改进模型。前者引入了大量噪声，未能达到预期效果，而后者略微提高了模型性能。最终模型对单词EERIE的预测为（0.649、7.579、26.298、32.614、20.930、9.63、2.298）。

Thirdly, K-means model is introduced to cluster the samples into 4 groups with the distribution of attempt times as the features by difficulty. In order to determine which features of the words are associated with the classifications, we used the classification as the output feature and all the attributes of the words as the input feature to establish a
LightGBM model for training. The accuracy of the test set reaches 70%. The importance of the output features is sorted. Finally, the model is used to predict the category of the EERIE word, and the prediction result is Group 2.

第三，引入K均值模型，将样本根据尝试次数的分布特征按难度分为4组。为了确定单词的哪些特征与分类相关，我们以分类作为输出特征，将单词的所有属性作为输入特征建立了一个LightGBM模型进行训练。测试集的准确率达到了70%。对输出特征的重要性进行了排序。最后，使用模型预测EERIE单词的类别，预测结果为第2组。

Finally, some interesting features of the dataset are found in dataset. The characteristics of large frequency words, the shape of distribution of attempt number and the correlation of the word features are discussed.

最后，在数据集中发现了一些有趣的特征。讨论了大频率单词的特征、尝试次数分布的形状以及单词特征的相关性。

In addition, we evaluated the advantages and disadvantages of the model and proposed some suggestions, and carried out a sensitivity analysis of the model to the commission rate, thereby proved the reliability and stability of the model.

此外，我们评估了模型的优缺点并提出了一些建议，还对模型对佣金率的敏感性进行了分析，从而证明了模型的可靠性和稳定性。

**Keywords**: Wordle ; ARIMA; LightGBM; MMoE; data augmentation; feature engineering; K-means; sensitivity analysis

关键词：Wordle；ARIMA；LightGBM；MMoE；数据增强；特征工程；K均值；敏感性分析

# 5. Uncover the Hidden Secrets in Wordle Results (2309397)
## 揭示Wordle结果中的隐藏秘密

Since Wordle has become a popular puzzle game, it has accumulated a large amount of data. In this paper, we define a series of metrics and build several models to explore the hidden information in Wordle results.

由于Wordle已成为一款热门的益智游戏，积累了大量的数据。本文定义了一系列的指标并构建了多个模型，以探索Wordle结果中的隐藏信息。

First, after preprocessing the given data and analyzing the time series diagram of the number of reported results, we found that the changes can be divided into 3 stages. To forecast the number of reported results, we developed a weighted optimization model based on ARIMA and BP neural network. The prediction interval is then given using the Bootstrap method. We packaged this process as ARIMA-BP Interval Prediction Model Based On Bootstrap. Thus, we finally predicted the interval prediction value obtained on March 1, 2023 at 95% confidence level to be about (19504.74, 20383.26).

首先，在对给定数据进行预处理并分析报告结果数量的时间序列图之后，我们发现变化可以分为3个阶段。为了预测报告结果的数量，我们基于ARIMA和BP神经网络开发了一个加权优化模型。然后使用Bootstrap方法给出了预测区间。我们将这个过程打包成基于Bootstrap的ARIMA-BP区间预测模型。因此，我们最终在95%置信水平下预测了2023年3月1日获得的区间预测值约为（19504.74, 20383.26）。

Then, we defined 3 qualitative and 4 quantitative attributes of words and used them to build a Multiple Linear Regression Model with the percentage of hard mode’s players. We found that the proportion will decrease by an average of 0.618 when the initial letter changes from a vowel to a consonant while it will increase by an average of 0.017 for 
each one-unit increase in word internal distance.

然后，我们定义了单词的3个定性属性和4个定量属性，并使用它们构建了一个与Hard Mode玩家的百分比相关的多元线性回归模型。我们发现，当初始字母从元音变为辅音时，比例平均减少0.618，而当单词内部距离每增加一个单位时，比例平均增加0.017。

After that, we made the percentage distribution prediction of the reported results based on LSTM Model. To ensure the percentage is around 100%, we first processed the component data using a spherical coordinate transformation. Then we use them as output variables, the 7 word attributes and number of results as input to train our LSTM model. The prediction of EERIE based on this are [2%, 11%, 25%, 24%, 19%, 14%, 5%]. We changed the model’s parameters and added noise to do sensitivity analysis.Meanwhile, we introduced COV to measure the uncertainty of the model prediction, and found that it is around 0.4. For error analysis, we use MSE, RMSE and R2 to measure the prediction accuracy, and their values are shown in Table 7.

之后，我们基于LSTM模型进行了报告结果的百分比分布预测。为了确保百分比在100%左右，我们首先使用球坐标变换处理了组件数据。然后，将它们作为输出变量，将7个单词属性和结果数量作为输入，来训练我们的LSTM模型。基于此的EERIE的预测值为[2%，11%，25%，24%，19%，14%，5%]。我们改变了模型的参数并添加了噪声进行敏感性分析。同时，我们引入了COV来衡量模型预测的不确定性，发现其约为0.4。对于误差分析，我们使用MSE、RMSE和R2来衡量预测的准确性，它们的值显示在表7中。

We extracted 6 indicators: RDC, TE, SK, NFC, NON, and HL to measure the difficulty of words. We built a GMM Clustering Model based on these indicators and thus classifying 5 difficulty levels. We classified the word EERIE as difficulty level III.

我们提取了6个指标：RDC、TE、SK、NFC、NON和HL来衡量单词的难度。我们基于这些指标构建了一个基于GMM的聚类模型，从而分类出5个难度级别。我们将单词EERIE分类为难度级别III。

In addition, by counting the frequency of each letter in five positions, we found S as the initial letter has the most frequency and more specific statistical results are shown in Table 9. We also used the Association Rule Model based on Apriori algorithm to mine the word combination pattern in Wordle. Ideally, we found that the letters A,S,E and F,T,L usually appear together in Wordle.

此外，通过统计每个位置上每个字母的频率，我们发现S作为初始字母的频率最高，更具体的统计结果显示在表9中。我们还使用基于Apriori算法的关联规则模型来挖掘Wordle中的单词组合模式。理想情况下，我们发现字母A、S、E和F、T、L通常会在Wordle中一起出现。

Finally, we evaluated and refined the model and reported the findings in a letter to the the Puzzle Editor of the New York Times.

最后，我们对模型进行了评估和优化，并将研究结果报告给《纽约时报》的拼图编辑。

**Keywords**: ARIMA-BP, LSTM, GMM, Apriori Algorithm, Word Attributes

关键词：ARIMA-BP，LSTM，GMM，Apriori算法，单词属性

# 6. Uncover the Puzzle of Words : Evidence from Wordle (2310767)
## 揭示文字谜题：来自Wordle的证据 

Using up to six guesses, players are asked to predict a five-letter word in Wordle, which provides feedback after each guess. We all know that different words have various characteristics that could influence how well a player performs. In this regard, our team modeled and evaluated the provided data to arrive at some intriguing conclusions.

在Wordle中，玩家被要求在最多六次猜测中预测一个五个字母的单词，每次猜测后都会提供反馈。我们都知道不同的单词具有各种特征，这些特征可能影响玩家的表现。在这方面，我们的团队对提供的数据进行了建模和评估，得出了一些有趣的结论。

For task 1, after data preprocessing, we first use the ARIMA model to forecast the number of reported results and find that it can only capture the linear part. Second, we take the LSTM model to capture the information of the non-linear part. Finally, we combine them to form ARIMA-LSTM model, which yields more accurate predictions with an RMSE of 0.0432. We finally arrive at a prediction interval of [9614,43109] for March 1, 2023. Subsequently, we define five word attributes, such as syllable count and entropy, and analyze their correlation with the percentage of people reporting scores in the difficult mode through the Spearman correlation coefficient, and find them to be significantly correlated.

对于任务1，在数据预处理之后，我们首先使用ARIMA模型预测报告结果的数量，并发现它只能捕捉线性部分。其次，我们使用LSTM模型捕捉非线性部分的信息。最后，我们将它们结合起来形成ARIMA-LSTM模型，其RMSE为0.0432，可以得到更准确的预测。我们最终得出了2023年3月1日的预测区间为[9614, 43109]。随后，我们定义了五个单词属性，如音节计数和熵，并通过Spearman相关系数分析它们与在困难模式下报告分数的百分比之间的关系，发现它们之间存在显著相关性。

For task 2, we use five preferred word attributes and competition number to predict the distribution of results using a stacking model that combines linear regression models (Ridge regression, Lasso regression) and tree models (XGBoost, LightGBM). We find that the stacking model improves the goodness of fit of the prediction results to 83.77%. Moreover, the MSE, RMSE, and MAE all indicate that the stacking model has a better capacity for learning. On March 1, 2023, the anticipated distribution of “EERIE” will be [1,2,3,4,5,6,X]=[0,0,9,18,26,37,10].

对于任务2，我们使用五个首选单词属性和竞争次数，使用堆叠模型（结合线性回归模型：岭回归，Lasso回归和树模型：XGBoost，LightGBM）来预测结果的分布。我们发现堆叠模型将预测结果的拟合度提高到了83.77%。此外，MSE、RMSE和MAE都表明堆叠模型具有更好的学习能力。到2023年3月1日，“EERIE”的预期分布将为[1,2,3,4,5,6,X]=[0,0,9,18,26,37,10]。

For task 3, we select seven additional word attributes to measure the words’ difficulty level, and then downscale the metrics by principal component analysis (PCA). We then use Gaussian Mixture Model(GMM) to cluster the words into three categories: difficult, moderate and easy. To get the true difficulty of the words, we calculate the expected number of tries for each word, which is used to compare with the classification results. It demonstrates that our model has a 67% accuracy rate. We explore interesting findings on the properties of the given words associated with each classification from three different perspectives: entropy, number of letters and frequency. Finally, we classified "EERIE" into the category of "difficult" based on its attribute.

对于任务3，我们选择了七个额外的单词属性来衡量单词的难度级别，然后通过主成分分析（PCA）对指标进行降维。然后，我们使用高斯混合模型（GMM）将单词分为三类：困难、中等和容易。为了获得单词的真实难度，我们计算了每个单词的预期尝试次数，用于与分类结果进行比较。结果表明我们的模型有67%的准确率。我们从三个不同的角度探讨了与每个分类相关的给定单词的属性的有趣发现：熵、字母数量和频率。最后，我们基于其属性将"EERIE"分类为"困难"类别。

For task 4, we perform a visual analysis of the provided dataset and discover some intriguing properties in three areas: (1) the number of reported results and the percentage of players who try the hard mode; (2) the distribution of tries; and (3) the frequency of letters in each position. These characteristics provide some interesting and feasible
ideas for players to solve the problem.

对于任务4，我们对提供的数据集进行了可视化分析，并在三个方面发现了一些有趣的特性：（1）报告结果的数量和尝试困难模式的玩家的百分比；（2）尝试的分布；（3）每个位置上字母的频率。这些特征为玩家解决问题提供了一些有趣而可行的想法。

We also conduct sensitivity analysis, which shows how different samples affect the word difficulty clustering model. And then the strengths and weaknesses of our model are summarized. Finally, a letter to the editor of the New York Times presenting the
overall ideas and results of our paper is written in the end of paper.

我们还进行了敏感性分析，展示了不同样本如何影响单词难度聚类模型。然后总结了我们模型的优势和劣势。最后，在论文末尾，我们写了一封给《纽约时报》编辑的信，介绍了论文的整体思想和结果。

**Keywords**: ARIMA-LSTM Model; Correlation Analysis; Stacking; PCA; GMM; Wordle;

关键词：ARIMA-LSTM模型；相关性分析；堆叠；PCA；GMM；Wordle；

# 7. Winners in Wordle (2311035)
## Wordle中的赢家

Wordle is a phenomenal network game. Its appearance intensely aroused people’s attention. Although it looks tiny, the hidden information behind it is huge and meaningful. Capturing and understanding this information will help the New York Times better design and operate Wordle.

Wordle是一款令人惊叹的网络游戏。它的出现引起了人们的强烈关注。尽管它看起来很小，但其背后隐藏的信息是巨大且有意义的。捕捉和理解这些信息将有助于《纽约时报》更好地设计和运营Wordle。

We built three models to finish the tasks. Model I uses LSTM to forecast the number of reported scores in the future. Model II uses seven XGBoost regressors to predict the percentage distribution of a given the word. Model III classifies words by their difficulties using SVM with RBF kernel. Based on our three models, we can provide some advice to help improve Wordle.

我们建立了三个模型来完成任务。模型I使用LSTM预测未来报告的得分数量。模型II使用七个XGBoost回归器预测给定单词的百分比分布。模型III使用带有RBF核的SVM对单词进行难度分类。基于我们的三个模型，我们可以提供一些建议，帮助改进Wordle。

The specific details are shown below:

具体细节如下：

Model I: LSTM is an improved recurrent neural network that can solve the long-distance dependence problem that other neural networks cannot handle. We trained processed data of the number of reported scores for the model and used an iterative method to predict the number until March 1st (2023). After 150 times of independent model training, the prediction interval is
[20745.72, 22914.74]. Additionally, from the linear regression on the proportion of hard mode with word attributes, we can also find no correlation between hard-mode-ratio and target word.

模型I：LSTM是一种改进的循环神经网络，可以解决其他神经网络无法处理的长距离依赖性问题。我们对模型进行了训练，使用处理过的报告分数数量的数据，并使用迭代方法预测到2023年3月1日的数量。经过150次独立模型训练，预测区间为[20745.72, 22914.74]。此外，从与单词属性相关的困难模式比例的线性回归中，我们还可以发现困难模式比例与目标单词之间没有相关性。

Model II: To get the percentage distribution of a given day associated with a specific word, we trained seven separate XGBoost models. The R2 of our model is 0.68, which can be accurately predicted with low uncertainty after testing. We apply "EERIE" to the model and gain a prediction percentage distribution, showing that ERRIE should be considered as an problematic word.

模型II：为了获得与特定单词相关的给定日期的百分比分布，我们训练了七个独立的XGBoost模型。我们的模型的R2为0.68，在测试后可以准确预测，具有低不确定性。我们将"EERIE"应用于模型，并获得了预测的百分比分布，显示ERRIE应该被视为一个问题单词。

Model III: We quantified the difficulty of words by the unequally weighted average of percentage distribution and divided them into three levels: easy, medium and hard. Then we used labeled to fit SVM model with RBF kernel and gain an accuracy score of 0.6556 and an F1 score of 0.6634. Also, the classification result for EERIE is hard, consistent with the result in model 2.

模型III：我们通过百分比分布的不平等加权平均值量化了单词的难度，并将它们分为三个级别：容易、中等和困难。然后，我们使用标签对带有RBF核的SVM模型进行拟合，并获得了0.6556的准确度分数和0.6634的F1分数。此外，EERIE的分类结果也是困难，与模型2的结果一致。

Except for these three models, we also found some interesting observations from the dataset, one of which discussed the differences between human thinking and machine learning.

除了这三个模型，我们还从数据集中发现了一些有趣的观察结果，其中一个讨论了人类思维与机器学习之间的差异。

Finally, we write a letter including our models, results, and advice to the New York Times Wordle editor. We hope this letter will become a valuable reference for the further development of Wordle.

最后，我们写了一封信，包括我们的模型、结果和建议，寄给了《纽约时报》的Wordle编辑。我们希望这封信能成为Wordle进一步发展的有价值的参考。

Keywords: Wordle; LSTM; Recursive Regression; XGBoost; Feature Engineering

关键词：Wordle；LSTM；递归回归；XGBoost；特征工程

# 8. Riddle of Wordle: Mining the Secret of Number Scores & Solution Words (2311717)
## Wordle之谜：挖掘数字得分和解答单词的秘密

Wordle is a popular puzzle currently offered daily by the New York Times. The simple rules and clever propagation properties have contributed to its popularity. In this article, we build two prediction models for the prediction of the Twitter report number intervals and result distributions, respectively, and develop a model for classifying the difficulty of solution words.

Wordle是一款目前由《纽约时报》每日提供的热门谜题。其简单规则和巧妙的传播特性促使了它的流行。在本文中，我们为Twitter报告数量间隔和结果分布的预测构建了两个预测模型，并开发了一个用于分类解答单词难度的模型。

In TASK 1: After data preprocessing, we build a Wordle report number prediction modelbased on 3rd-order gaussian regression and a non-homogeneous Poisson process from a statistical perspective. Among them, the Gaussian regression is used to predict the trend signs of report numbers, while the non-homogeneous Poisson process predicts the stochastic fluctuations of report numbers on this basis. Moreover, we use the popularity relaxation function to correct the stochastic process, which better approximates the popularity change. At a confidence level of 75%, we predict the interval of the number of reports on March 1, 2023 to be [7654, 20154]. In addition, we extract 8 attributes of words in terms of the number of letters, letter location and so on, finding that these attributes did not have an effect on the percentage of players' Hard Mode choices. Players' confidence in their performance ability and their play mentality may be the main reasons for whether they choose the Hard Mode or not.

在任务1中：经过数据预处理后，我们从统计的角度建立了一个基于三阶高斯回归和非齐次Poisson过程的Wordle报告数量预测模型。其中，高斯回归用于预测报告数量的趋势标志，而非齐次Poisson过程在此基础上预测报告数量的随机波动。此外，我们使用流行度松弛函数来修正随机过程，从而更好地逼近流行度变化。在75%的置信水平下，我们预测2023年3月1日的报告数量区间为[7654, 20154]。此外，我们从字母数量、字母位置等方面提取了8个单词的属性，发现这些属性对玩家选择困难模式的百分比没有影响。玩家对自己表现能力的信心和他们的游戏心态可能是选择是否选择困难模式的主要原因。

In TASK 2: We first extract the data features that affect the distribution of reported results, including word attributes, and the percentage of difficulty patterns. Then, we build a BP neural network to make preliminary predictions on the distribution of guessing results for a certain solution word in the future. To improve the generalization performance of the prediction results, we build an integrated BP neural network based on Bagging. Then, we predict the distribution of the reported results of EERIE on March 1, 2023 as (0, 1, 6, 25, 31, 25, 13) (in %). We have more than 80% confidence that the absolute error of the predicted outcome for the percentage of each possible result does not exceed 5%. 

在任务2中：我们首先提取影响报告结果分布的数据特征，包括单词属性和难度模式的百分比。然后，我们建立了一个BP神经网络，对未来某个解答单词的猜测结果分布进行初步预测。为提高预测结果的泛化性能，我们基于Bagging构建了一个综合的BP神经网络。然后，我们预测了2023年3月1日EERIE的报告结果分布为（0, 1, 6, 25, 31, 25, 13）（以%表示）。我们有超过80%的置信度，预测结果中每种可能结果的绝对误差不会超过5%。

In TASK 3: First, we build a word difficulty induction model based on the K-Means from the distribution of user's reported data, and divide the difficulty into 4 classes. Then, we explore the association between word attributes and difficulty based on Pearson’s coefficients, and take the attributes with correlation coefficients greater than 0.6 as difficulty classification attributes to build a word difficulty classification model. Moreover, we find that the frequency of the first and second letters of the solution words, the number of vowels contained in the pronunciation and the number of word properties have a high correlation with the difficulty classification. Finally, the difficulty classification result of EERIR is the most difficult.

在任务3中：首先，我们从用户报告数据的分布中基于K-Means构建了一个单词难度归纳模型，并将难度分为4个类别。然后，我们通过Pearson相关系数探索单词属性与难度之间的关联，并将相关系数大于0.6的属性作为难度分类属性构建单词难度分类模型。此外，我们发现解答单词的前两个字母的频率、发音中包含的元音数量和单词属性的数量与难度分类之间有很高的相关性。最后，EERIR的难度分类结果是最难的。

In TASK 4: While exploring the statistical properties of the number of reports, we find that the distribution of the number of reports showed a similar pattern to its trend over time. In addition, we also notice that the percentage fluctuation of 3 tries to complete the game was the largest in the 359 days of reported outcome distribution data.

在任务4中：在探索报告数量的统计特性时，我们发现报告数量的分布呈现出与其随时间变化的趋势类似的模式。此外，我们还注意到在359天的报告结果分布数据中，完成游戏的3次尝试的百分比波动是最大的。

Finally, we perform a sensitivity analysis of the model and investigate the effect of changes in the variable parameters of the model on the results.

最后，我们对模型进行了敏感性分析，研究了模型变量参数变化对结果的影响。

Keywords: Gaussian regression; Poisson process; BP neural network; K-Means

关键词：高斯回归；Poisson过程；BP神经网络；K-Means

# 9. Breaking the Wordle (2314151)
## 揭秘Wordle

As Wordle has become popular on social media, more and more users have played the scrabble game. How do time and word attributes affect the number of reports, distribution of attempts, and other report-related information? Therefore, a modeling analysis was conducted using the game data from 2022.

随着Wordle在社交媒体上变得流行，越来越多的用户参与了这个拼字游戏。时间和单词属性如何影响报告数量、尝试分布以及其他与报告相关的信息？因此，使用来自2022年的游戏数据进行了建模分析。

Before building the model, we cleaned and normalized the given data and identified word attributes such as the number of repeated letters, number of vowel letters, number of consonant letters, commonness, and frequency. Preliminary preparations were made for model building and solving.

在构建模型之前，我们清理和规范了给定的数据，并确定了诸如重复字母数量、元音字母数量、辅音字母数量、普遍性和频率等单词属性。为模型构建和解决问题做了初步准备。

First, to predict the number of future reports, a prophet-based time-series prediction model was built, considering the effects of trends, seasonality, and holidays. The predictions yielded a range of report numbers for March 1, 2023: [10355,18742]. Regarding the variation of report numbers, during the week, the number of reports tends to be highest on Wednesdays and lowest on weekends. In exploring the effect of word attributes on the proportion of difficulty reports, we calculated higherorder partial correlation coefficients for both, controlling for the interaction between word attributes, and found that the number of vowel letters, the number of non-repeats, and word commonness were negatively correlated. The number of consonant letters and the number of non-repeats was positively correlated.

首先，为了预测未来报告的数量，我们构建了基于Prophet的时间序列预测模型，考虑了趋势、季节性和假期的影响。预测结果得出了2023年3月1日的报告数量范围：[10355, 18742]。关于报告数量的变化，在一周之内，报告数量在周三最高，在周末最低。在探讨单词属性对困难报告比例的影响时，我们计算了两者的高阶偏相关系数，控制了单词属性之间的相互作用，发现元音字母的数量、非重复数量和单词的普遍性呈负相关，辅音字母的数量和非重复数量呈正相关。

Secondly, an optimized multi-objective regression prediction framework was developed to explore the effects of word attributes on the distribution of reported outcomes. The framework chose the optimal lasso regression to predict the test set with an RMSE of 0.80. The distribution of the number of attempts to predict ’EERIE’ was (0, 4, 17, 34, 30, 13, 2). The ranking importance of each attribute was calculated, and it was found that the number of consonant letters, number of vowel letters, and frequency had a more significant influence on the distribution of reported results with the influence factors of 4.226, 3.993, and 1.253, respectively.

其次，我们开发了一个优化的多目标回归预测框架，探讨了单词属性对报告结果分布的影响。该框架选择了最优的Lasso回归来预测测试集，RMSE为0.80。预测'EERIE'的尝试次数分布为（0, 4, 17, 34, 30, 13, 2）。计算了每个属性的排名重要性，发现辅音字母的数量、元音字母的数量和频率对报告结果分布有更显著的影响，其影响因子分别为4.226、3.993和1.253。

Next, the above model was used to predict the distribution of reported outcomes for each word in the 5-letter word set. Then, K-means was used to classify the words into high (≥4.37), medium (4.13- 4.37), and low (<4.13) difficulty categories based on the average number of attempts, and it was found that the Number of duplicates, Maximum of repeats, Prevalence and Frequency differed significantly across categories. Moreover, the interval of each attribute was divided. According to the established model, ’EERIE’ is difficult. The model’s accuracy is 91.36 %by matching the attribute intervals for different difficulty words, and it can be inferred that the established model and the divided attribute intervals are reasonable.

接下来，上述模型被用于预测5个字母单词集中每个单词的报告结果分布。然后，使用K-means将单词分为高（≥4.37）、中（4.13-4.37）和低（<4.13）难度类别，基于平均尝试次数，发现重复数量、最大重复次数、流行度和频率在不同类别之间有显著差异。此外，还划分了每个属性的区间。根据建立的模型，'EERIE'是困难的。通过匹配不同难度单词的属性区间，模型的准确性为91.36%，可以推断建立的模型和划分的属性区间是合理的。

Finally, the sensitivity analysis results demonstrate that our model is robust and reliable. In addition, The study of the data set also revealed the declining popularity of Wordle and the increasing percentage of difficult mode challenges, and provided the New York Times with suggestions for restoring the game’s popularity.

最后，敏感性分析的结果表明我们的模型是健壮而可靠的。此外，对数据集的研究还揭示了Wordle的流行度下降和困难模式挑战的百分比增加，并为《纽约时报》提供了恢复游戏流行度的建议。

**Keywords**: Wordle analysis, Prophet, High-order partial correlation, Multi-objective regression
forecasting, K-means

关键词：Wordle分析，Prophet，高阶偏相关，多目标回归预测，K-means

# 10. Exploring Wordle: Insights into Puzzle Solving and Tweet Shares Pattern (2318036)
## 探索Wordle：拼图解谜和推特分享模式的洞见

Wordle, a word puzzle that has attracted millions of people, is now owned by The New York Times. For the company’s game editor, how the game is solved and shared on social media is critical information, as it can be used to guide future puzzle design and ultimately maximise the total number of players. This paper aims to build a quantitative model based on word attributes and result reports on Twitter to predict the future pattern of players.

Wordle是一款吸引了数百万人的文字拼图游戏，现在由《纽约时报》拥有。对于公司的游戏编辑来说，游戏如何解决并在社交媒体上分享是关键信息，因为它可以用来指导未来拼图设计，并最终最大化玩家总数。本文旨在基于单词属性和推特上的结果报告构建一个定量模型，以预测玩家未来的模式。

After examining and cleaning the raw data, we first define 12 attribute indicators measuring its familiarity (how often used), degree of association, degree of confusion and word composition features. They are computed in advance because the following models will frequently use these indicators.

在检查和清理原始数据后，我们首先定义了12个属性指标，用于衡量单词的熟悉程度（使用频率）、关联程度、混淆程度和单词组成特征。它们被预先计算，因为接下来的模型将经常使用这些指标。

For Problem 1, we build a dynamic system called Target-two-Players-Lost (T2PL) based on the SIR Model to explain the daily fluctuation of Wordle reports. Players are additionally divided into two categories: general players and loyal players, each with a different attrition rate. This allows the model to simulate unequal decline rates over different time periods better. The relationship between word attributes and the number of hard mode players is also explored, and it is found that certain attributes affect the percentage of Hard Mode reports.

对于问题1，我们构建了一个基于SIR模型的动态系统，称为Target-two-Players-Lost（T2PL），以解释Wordle报告的日常波动。玩家被额外分为两类：普通玩家和忠实玩家，每类都有不同的减员率。这使得模型能够更好地模拟不同时间段内不均等的下降速度。还探讨了单词属性与Hard Mode玩家数量的关系，发现某些属性影响Hard Mode报告的百分比。

For Problem 2, we develop a P&S Model, which is a model that uses simulation algorithms and gradient descent to mimic the behavior of players in guessing words and sharing the game results. The simulator works by eliminating all unsatisfactory words using observable information, then randomly sampling words from the remaining word list using word frequency as the weight. However, we found that the simulation result could not perfectly match the true distribution. Therefore, we rescaled the distribution with 7 variables representing how players are likely to share their score when given different scores. They are optimised by gradient descent, and better distribution predictions could be generated. Using the P&S Model, we predict the distribution of the word EERIE on March 1, 2023 is (0, 0, 9%, 29%, 45%, 14%, 3%).

对于问题2，我们开发了一个P&S模型，这是一个使用模拟算法和梯度下降来模拟玩家猜测单词和分享游戏结果行为的模型。该模拟器通过使用可观察信息消除所有不满意的单词，然后从剩余的单词列表中随机抽样，使用单词频率作为权重。然而，我们发现模拟结果无法完全匹配真实分布。因此，我们使用了7个表示在给定不同分数时玩家可能分享他们的得分的变量来重新缩放分布。它们通过梯度下降进行优化，可以生成更好的分布预测。使用P&S模型，我们预测了2023年3月1日单词EERIE的分布为（0, 0, 9%，29%，45%，14%，3%）。

For Problem 3, we are required to classify puzzles by difficulty. We perform a cluster analysis on all reported trial distributions using 3 clusters K-means, with each cluster labelled easy, medium and hard. We fit a Random Forest Model to divide the words into these three categories using the attribute indicators defined at the beginning. The correlation coefficient between each indicator and the difficulty is calculated, showing the direction in which these indicators affect the difficulty of the puzzles. The sensitivity of the clustering is discussed as well. Based on our model, the difficulty of EERIE is hard.

对于问题3，我们需要根据难度对拼图进行分类。我们对所有报告的试验分布进行了聚类分析，使用3个簇的K均值，每个簇标记为容易、中等和困难。我们使用随机森林模型根据开始时定义的属性指标将单词分成这三类。计算了每个指标与难度之间的相关系数，显示了这些指标影响拼图难度的方向。还讨论了聚类的敏感性。根据我们的模型，EERIE的难度是困难的。

For Problem 4, we further explore the effects of word difficulty. Using Linear Regression, we found that word difficulty has an obvious effect on the number of results reported: harder puzzles lead to fewer reports. Difficulty also correlates with the percentage of people choosing Hard Mode, as we mentioned earlier. Through this part of the study, we find that the correlation is formed by word difficulty affecting the number of Normal Mode players.

对于问题4，我们进一步探讨了单词难度的影响。通过使用线性回归，我们发现单词难度明显影响报告的结果：更难的拼图导致报告较少。难度还与选择Hard Mode的人数的百分比相关，正如我们之前提到的。通过这部分研究，我们发现相关性是由单词难度影响Normal Mode玩家数量而形成的。

With all the uncovered interactions between word attributes, puzzle difficulty, and game report patterns, Wordle operators could gain a deeper understanding of their players. Several sensible suggestions could also be made based on this discovery.

通过揭示单词属性、拼图难度和游戏报告模式之间的所有相互作用，Wordle的运营商可以更深入地了解他们的玩家。基于这一发现，还可以提出一些明智的建议。

**Keywords**: Wordle; Dynamic system; Simulation; K-means; Random Forest

关键词：Wordle；动态系统；模拟；K均值；随机森林

# 11. Wordle: One Letter Makes a Difference (2318982)
## Wordle: 一个字母的差异

Since its launch in early 2022, Wordle has sparked a wave of sharing yellow, green and grey squares on social media. Wordle has simple but challenging rules that requiring only a short attention span. Based on the Wordle dataset, we dig into the information hidden behind the number and the percentage of reported results.

自2022年初推出以来，Wordle在社交媒体上引发了一波分享黄色、绿色和灰色方块的热潮。Wordle拥有简单但具有挑战性的规则，只需要短暂的注意力。基于Wordle数据集，我们深入挖掘了数字和报告结果百分比背后隐藏的信息。

First, we focus on the number of reported results that varies over time. We try to build an ARIMA model providing us with a prediction interval for the number of reported results on March 1, 2023. It indicates that the Wordle still maintains a high level of enthusiasm one year after its release. Then, we explore the factors influencing the percentage of Hard Mode. By fitting a multiple linear regression model, the results show that the number of repeated letters and the frequency of words are correlated with the difficulty of the game. The difficulty information that players obtained from the community in advance may influence their choice of game mode.

首先，我们关注随时间变化的报告结果数量。我们尝试构建一个ARIMA模型，为我们提供2023年3月1日报告结果数量的预测区间。它表明Wordle在发布一年后仍然保持着高水平的热情。然后，我们探讨影响Hard Mode百分比的因素。通过拟合多元线性回归模型，结果显示重复字母的数量和单词的频率与游戏的难度相关。玩家在社区中提前获取的游戏难度信息可能影响他们选择的游戏模式。

Next, we are curious how the distribution of the reported results would change in the future. To simplify the model, we generalize the player’s game states to their known number of squares of each color. Wordle can then be modeled as a Markov chain, and the problem is transformed into solving the first-arrival distribution of it. This requires knowledge of the initial distribution and transfer probabilities relying on the strategies chosen by players. In addition, the transfer
probability is assumed to depend on the difference in the amount of information between states. So we propose a method to measure the current amount of information in the states. Based on this, we model the entire Markov chain and solve the first reach-time distribution under different strategies.

接下来，我们想知道报告结果的分布在未来会如何变化。为了简化模型，我们将玩家的游戏状态概括为他们已知每种颜色方块的数量。然后，Wordle可以被建模为马尔可夫链，问题被转化为解决其首次到达分布。这需要了解初始分布和依赖玩家选择的策略的转移概率。此外，假设转移概率取决于状态之间信息量的差异。因此，我们提出了一种测量状态当前信息量的方法。基于此，我们建模整个马尔可夫链，并在不同策略下解决首次达到时间分布。

To make the model more reasonable, it is assumed that the proportion of people choosing the above two strategies varies with time. Accordingly, a method based on historical data is proposed to estimate this proportion. Finally, we combine the estimated proportion with a Gaussian process regression model to predict the future proportion of player strategy choices. This is then combined with the Markov chains model to predict the distribution of future reported results. We finally obtain the distribution of EERIE, which is (0.00, 0.15, 11.05, 28.44, 35.46, 21.16, 3.76).

为了使模型更加合理，假设选择上述两种策略的人的比例随时间变化。因此，提出了一种基于历史数据的方法来估计这个比例。最后，我们将估计的比例与高斯过程回归模型结合起来，以预测未来玩家策略选择的比例。然后将其与马尔可夫链模型结合起来，以预测未来报告结果的分布。最终，我们得到了EERIE的分布，为（0.00，0.15，11.05，28.44，35.46，21.16，3.76）。

Finally, we want to classify words according to their difficulty. Since word difficulty is only related to the word itself, it is believed that clustering according to word attributes can reflect the difficulty level of words. For this idea,K-Prototypes clustering is performed and reasonable word difficulty index is set. Then, we extract the difficulty information of each category, and then plot the density function and calculate Kullback-Leibler divergence. Both of results show that words with different attributes have different difficulty levels. It proves that our idea is reasonable and the classification model is accurate. Further, we classify the EERIE into “hard” class by its attributes, which is consistent with the percentage distribution obtained above. In addition, we discuss other information about the dataset, such as the difficult words, the easy words and the unexpected words. Finally, the sensitivity analysis of the model shows the good robustness of our model.

最后，我们希望根据它们的难度对单词进行分类。由于单词的难度仅与单词本身有关，因此认为根据单词属性进行聚类可以反映单词的难度水平。为了实现这一想法，执行了K-Prototypes聚类，并设置了合理的单词难度指数。然后，我们提取每个类别的难度信息，然后绘制密度函数并计算Kullback-Leibler散度。结果都显示具有不同属性的单词具有不同的难度水平。这证明了我们的想法是合理的，分类模型是准确的。此外，我们通过其属性将EERIE分类为“困难”类别，与上面获得的百分比分布一致。此外，我们还讨论了数据集的其他信息，如难词、简单词和意外词。最后，模型的敏感性分析显示了我们模型的良好稳健性。

**Keywords**: ARIMA; multiple linear regression; Markov chains; K-Prototypes clustering

关键词：ARIMA；多元线性回归；马尔可夫链；K-Prototypes聚类

# 12. No Title (2322645)
## 无标题

With the rising popularity of Wordle, people have eagerly taken to Twitter to report their results daily by the tens of thousands. Three very natural questions arise regarding this data: (1) Can we use this data to predict the difficulty of a given target word in Wordle? (2) Can we use this data to predict future Wordle player reporting trends? (3) How does the difficulty of given target word affect player reporting and results? In our paper, we develop a comprehensive Bayesian model consisting of three submodels which predict the distribution of the number of guesses, number of reported results on Twitter and the number of reporting players playing in hard mode.

随着Wordle的日益流行，成千上万的人们每天都迫不及待地通过Twitter报告他们的结果。关于这些数据，有三个非常自然的问题：(1) 我们能否利用这些数据来预测Wordle中给定目标单词的难度？(2) 我们能否利用这些数据来预测未来Wordle玩家的报告趋势？(3) 给定目标单词的难度如何影响玩家的报告和结果？在我们的论文中，我们开发了一个包含三个子模型的综合贝叶斯模型，这三个子模型分别预测了猜测次数的分布、Twitter上报告的结果数量以及以困难模式进行游戏的报告玩家数量。

Initially, we decompose words into quantifiable traits associated with relevant difficulty characteristics. Most notably, we formulate a novel Wordlespecific entropy measure we call Subset Entropy which effectively quantifies the average amount of information revealed by typical players after initial guesses. We also develop a method to represent the distribution of player attempts, and hence the observed difficulty of a word, using just two values α, β corresponding to the cumulative mass function of the Beta distribution. We use a preliminary Lasso regression to isolate the most relevant predictors of word difficulty, which we then use in our Bayesian model.

首先，我们将单词分解为与相关难度特征相关的可量化特征。特别值得注意的是，我们制定了一种新颖的Wordle特定熵度量，我们称之为子集熵，它有效地量化了典型玩家在初始猜测后透露的平均信息量。我们还开发了一种表示玩家尝试分布的方法，因此也就是单词的观察难度，仅使用两个值α、β对应于Beta分布的累积质量函数。我们使用初步的Lasso回归来分离单词难度的最相关预测因子，然后将其用于我们的贝叶斯模型。

Our Bayesian model predicts, for a given date and word, the reported difficulty of a word, the number of player reports, and the number of players reporting playing in hard-mode. To accomplish these three tasks, it is made up of three submodels which are conditionally independent given the data, making it efficient to sample from its posterior using Markov Chain MonteCarlo (MCMC).

我们的贝叶斯模型预测了给定日期和单词的单词难度、玩家报告数量以及以困难模式报告玩家数量。为了完成这三项任务，它由三个子模型组成，这三个子模型在给定数据的条件下是相互独立的，使得从其后验中抽样变得更加高效，使用马尔可夫链蒙特卡洛(MCMC)。

We find that a word having a higher number of unique letters, usage frequency in English, average number of revealed yellow squares over all guesses, and Subset Entropy all make a word easier for players to guess. We also find that higher word difficulty decreases the number of player reports. Under the assumption that the Times choose words randomly, this can be
interpreted as a causal effect.

我们发现，具有更多唯一字母、在英语中的使用频率、在所有猜测中揭示的黄色方块的平均数量以及子集熵的单词更容易被玩家猜测。我们还发现，更高的单词难度会减少玩家报告的数量。在假设时报随机选择单词的情况下，这可以解释为因果效应。

Our model is able to predict outcomes for new data and retrodict for old data. Our model gives gives a 95% prediction interval that between 20238 and 27876 players will report results for “eerie” on March 1, 2023 and that it will be in the 50th percentile of difficulty. Most notably, our model does not just provide such simple point estimates and prediction intervals, but full posterior distributions.

我们的模型能够预测新数据的结果并为旧数据提供反事实预测。我们的模型给出了95%的预测区间，即2023年3月1日将有20238到27876名玩家报告“eerie”的结果，并且它将处于难度的50th百分位数。特别值得注意的是，我们的模型不仅提供简单的点估计和预测区间，还提供完整的后验分布。

**Keywords**: Entropy, Lasso regression, MCMC, Bayesian methods, Causal inference

关键词：熵，Lasso回归，MCMC，贝叶斯方法，因果推断
